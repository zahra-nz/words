{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kc8j6ASbHeG"
      },
      "outputs": [],
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download fr_core_news_md\n",
        "!pip install pdfplumber\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pdfplumber\n",
        "\n",
        "# window for uploading\n",
        "uploaded = files.upload()\n",
        "\n",
        "# getting the name of the uploaded dossier\n",
        "pdf_path = list(uploaded.keys())[0]\n",
        "\n",
        "# extracting text\n",
        "text = \"\"\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            text += page_text + \"\\n\"\n",
        "\n",
        "# first 100 char of the text\n",
        "print(text[:1000])\n"
      ],
      "metadata": {
        "id": "bILVnhGVbKUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = input(\"Ù„Ø·ÙØ§Ù‹ Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ (Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ±Ø§Ù†Ø³ÙˆÛŒ) Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: \")\n"
      ],
      "metadata": {
        "id": "Kd8txzTsb56i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words_fr = set(stopwords.words('french'))\n"
      ],
      "metadata": {
        "id": "di8L2m73fx6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words_fr = set(stopwords.words('french'))\n",
        "\n",
        "def get_context_words(text, keyword, window=2):\n",
        "    tokens = word_tokenize(text, language='french')\n",
        "    contexts = []\n",
        "    for i, token in enumerate(tokens):\n",
        "        if token.lower() == keyword.lower():\n",
        "            start = max(0, i - window)\n",
        "            end = min(len(tokens), i + window + 1)\n",
        "            context = tokens[start:i] + tokens[i+1:end]\n",
        "            context_filtered = [\n",
        "                w.lower() for w in context\n",
        "                if w.lower() not in stop_words_fr\n",
        "                and w.lower() not in string.punctuation\n",
        "                and w.isalpha()\n",
        "            ]\n",
        "            contexts.append(context_filtered)\n",
        "    return contexts\n"
      ],
      "metadata": {
        "id": "wDQ0fjz4csxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "# std french stop words\n",
        "nltk.download('stopwords')\n",
        "stop_words_fr = set(stopwords.words('french'))\n",
        "\n",
        "# mnl stop words\n",
        "custom_stopwords = {\n",
        "    'et', 'ou', 'le', 'la', 'un', 'une', 'du', 'de', 'des', 'Ã ',\n",
        "    ',', '.', ';', ':', '!', '?', 'lâ€™', 'dâ€™', 'â€“', '-', 'Â«', 'Â»',\n",
        "    'dans', 'en', 'pour', 'avec', 'par', 'sur', 'au', 'aux', 'ce', 'cet',\n",
        "    'cette' , \"ainsi\" , \",\" , \"plus\", \"tout\", \"comme\", \"a\", \"aux\", \"ainsi\", \"alors\", \"aprÃ¨s\", \"aucun\", \"aucune\",\n",
        "    \"autre\", \"avant\", \"avec\", \"avoir\", \"Ã§a\", \"car\", \"ce\", \"cela\", \"cette\", \"cet\", \"ces\",\n",
        "    \"cette\", \"dans\", \"donc\", \"dont\", \"du\", \"elle\", \"en\", \"est\", \"et\", \"eux\", \"il\", \"ils\",\n",
        "    \"je\", \"lÃ \", \"la\", \"le\", \"les\", \"leur\", \"lui\", \"ma\", \"mais\", \"me\", \"mÃªme\", \"mes\",\n",
        "     \"moi\", \"mon\", \"ne\", \"nos\", \"notre\", \"nous\", \"on\", \"ou\", \"oÃ¹\", \"par\", \"pas\", \"pour\",\n",
        "      \"quand\", \"que\", \"qui\", \"sa\", \"se\", \"ses\", \"si\", \"son\", \"sont\", \"sur\", \"ta\", \"te\",\n",
        "       \"tes\", \"toi\", \"ton\", \"tous\", \"tout\", \"trop\", \"tu\", \"un\", \"une\", \"vos\", \"votre\",\n",
        "      \"vous\", \"y\" , \"of\" , \"the\" , \"in\" , \"for\" , \"b\" , \"and\" , \"vol\" , \"e\" , \"r\" , \"f\" ,\n",
        "        \"v\" , \"ser\" , \"loi\" , \"re\" , \"sie\" , \"don\" , \"mots\" , \"titre\" ,  \"article\", \"code\",\n",
        "        \"art\", \"alinÃ©a\", \"mots\", \"remplace\", \"etat\", \"Ã‰tat\",\n",
        "       \"rÃ©digÃ©\", \"disposition\", \"titre\", \"ar\", \"dÃ©cret\", \"ministre\", \"ii\", \"l\"\n",
        "        \"modifiÃ©\", \"prÃ©sident\", \"mentionnÃ©s\", \"prÃ©sent\", \"articles\", \"cas\",\n",
        "         \"modifie\", \"prÃ©sente\", \"gÃ©nÃ©ral\", \"reprÃ©sentant\", \"texte\" , \"ticle\"\n",
        "         , \"genre\" , \"Conditions\" , \"Tacle\" , \"Charge\" , \"parc\" , \".\" , \";\" , \":\" , \"Â»\"\n",
        "}\n",
        "\n",
        "stop_words_fr |= custom_stopwords\n"
      ],
      "metadata": {
        "id": "XNiG2OqqhZGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"âš ï¸ Ú†Ù†Ø¯ stopword ÙØ±Ø§Ù†Ø³ÙˆÛŒ:\")\n",
        "print(list(stop_words_fr)[:20])\n"
      ],
      "metadata": {
        "id": "Yle_M0llgkT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# just keep the alph/non-fr stop words\n",
        "flat_words = [\n",
        "    w.lower() for ctx in contexts for w in ctx\n",
        "    if w.lower() not in stop_words_fr and w.isalpha()\n",
        "]\n",
        "\n",
        "most_common = Counter(flat_words).most_common(10)\n",
        "\n",
        "print(\"ğŸ“Š Û±Û° Ú©Ù„Ù…Ù‡ Ù¾Ø±ØªÚ©Ø±Ø§Ø± Ø§Ø·Ø±Ø§Ù Ú©Ù„Ù…Ù‡ Ú©Ù„ÛŒØ¯ÛŒ (ÙÛŒÙ„ØªØ±Ø´Ø¯Ù‡):\")\n",
        "for word, count in most_common:\n",
        "    print(f\"{word}: {count} Ø¨Ø§Ø±\")\n"
      ],
      "metadata": {
        "id": "7utB180fc5uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import CamembertModel, CamembertTokenizer\n",
        "import torch\n",
        "\n",
        "# Frnch model and tokenizer\n",
        "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
        "model = CamembertModel.from_pretrained(\"camembert-base\")\n"
      ],
      "metadata": {
        "id": "VgAmZJh6c-hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :]  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² [CLS] ØªÙˆÚ©Ù† Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ\n"
      ],
      "metadata": {
        "id": "4ogJ-Pm4dH1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :]  # using CLS\n"
      ],
      "metadata": {
        "id": "WYOwTuiglxd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words_fr = set(stopwords.words('french'))\n"
      ],
      "metadata": {
        "id": "6qCmycySeAB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def analyze_similarity(contexts):\n",
        "    sentences = [\" \".join(ctx) for ctx in contexts]\n",
        "    embeddings = [get_embedding(sen) for sen in sentences]\n",
        "\n",
        "    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† embedding Ú©Ù„ Ø²Ù…ÛŒÙ†Ù‡â€ŒÙ‡Ø§\n",
        "    avg_embedding = torch.stack(embeddings).mean(dim=0)\n",
        "\n",
        "    seen_words = set()\n",
        "    similarities = []\n",
        "\n",
        "    for context in contexts:\n",
        "        for word in context:\n",
        "            if word in seen_words:\n",
        "                continue\n",
        "            seen_words.add(word)\n",
        "            try:\n",
        "                emb = get_embedding(word)\n",
        "                sim = cosine_similarity(emb, avg_embedding).item()\n",
        "                similarities.append((word, sim))\n",
        "            except:\n",
        "                continue  # Ø§Ú¯Ø± embedding Ù†Ú¯Ø±ÙØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡\n",
        "\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:10]\n"
      ],
      "metadata": {
        "id": "jTc3FdazdOi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import string\n",
        "\n",
        "def analyze_similarity(contexts):\n",
        "    sentences = [\" \".join(ctx) for ctx in contexts]\n",
        "    embeddings = [get_embedding(sen) for sen in sentences]\n",
        "\n",
        "    avg_embedding = torch.stack(embeddings).mean(dim=0)\n",
        "\n",
        "    similarities = []\n",
        "    seen_words = set()\n",
        "\n",
        "    for context in contexts:\n",
        "        for word in context:\n",
        "            word_clean = word.lower()\n",
        "\n",
        "            #filter\" stop word, pubctuation, numbers, already seen words\n",
        "            # ÙÛŒÙ„ØªØ±: Ø§Ø³ØªØ§Ù¾â€ŒÙˆØ±Ø¯ØŒ Ø¹Ù„Ø§Ù…Øªâ€ŒÙ†Ú¯Ø§Ø±Ø´ÛŒØŒ Ø¹Ø¯Ø¯ØŒ Ùˆ ØªÚ©Ø±Ø§Ø±ÛŒ\n",
        "            if (word_clean in stop_words_fr or\n",
        "                word_clean in string.punctuation or\n",
        "                not word_clean.isalpha() or\n",
        "                word_clean in seen_words):\n",
        "                continue\n",
        "\n",
        "            seen_words.add(word_clean)\n",
        "\n",
        "            try:\n",
        "                emb = get_embedding(word_clean)\n",
        "                sim = cosine_similarity(emb, avg_embedding).item()\n",
        "                similarities.append((word_clean, sim))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:10]\n"
      ],
      "metadata": {
        "id": "1yAFNPKjl2Zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_top = analyze_similarity(contexts)\n",
        "\n",
        "print(\"\\nğŸ’¡ Û±Û° Ú©Ù„Ù…Ù‡ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø´Ø¨Ø§Ù‡Øª Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡â€ŒÛŒ Ø§Ø·Ø±Ø§Ù Â«{}Â»:\".format(keyword))\n",
        "for word, score in semantic_top:\n",
        "    print(f\"{word}: {score:.4f}\")\n"
      ],
      "metadata": {
        "id": "erMexeUQl7wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''semantic_top = analyze_similarity(contexts)\n",
        "\n",
        "print(\"\\nğŸ’¡ Û±Û° Ú©Ù„Ù…Ù‡ Ø¨Ø§ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø´Ø¨Ø§Ù‡Øª Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ù‡ Ø²Ù…ÛŒÙ†Ù‡â€ŒÛŒ Ø§Ø·Ø±Ø§Ù Â«{}Â»:\".format(keyword))\n",
        "for word, score in semantic_top:\n",
        "    print(f\"{word}: {score:.4f}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2k_tptJudSdr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}